# ğŸ¤– AutoData Agent â€“ Autonomous Hugging Face AI for Data Cleaning & Modeling

<div align="center">
  <img src="https://huggingface.co/front/assets/huggingface_logo.svg" width="120"/>
  <h3>An autonomous data science agent that cleans, explores and models your data intelligently ğŸ§ </h3>
  <p>Built with <b>Hugging Face SmolAgents</b>, <b>Ollama</b>, and <b>Scikit-Learn</b></p>
</div>

---

## ğŸ§  Project Overview

**AutoData Agent** is a modular and autonomous data assistant designed to:

* ğŸ§¹ **Inspect** raw datasets (missing values, data types, anomalies)
* ğŸ§¼ **Clean** and preprocess data (imputation, encoding, scaling)
* ğŸ“Š **Visualize** key statistical properties (distributions, correlations, boxplots)
* ğŸ¤– **Train machine learning models** automatically (classification or regression)
* âš™ï¸ **Optimize** the model using GridSearchCV to achieve best performance

This project demonstrates how a **Hugging Face agent** can orchestrate an end-to-end **Data Science pipeline**,  making smart decisions and reasoning about the dataset structure.

---

## ğŸ§© Architecture

```bash
datacleaner-agent/
â”œâ”€â”€ app.py                 # Main entry point
â”œâ”€â”€ agent_logic.py         # Builds the Hugging Face Agent (model + tools)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ inspect.py         # InspectTool: automatic EDA (plots + summary)
â”‚   â”œâ”€â”€ cleaning.py        # CleaningTool: data cleaning & encoding
â”‚   â””â”€â”€ train.py           # TrainTool: automatic ML training + evaluation
â”œâ”€â”€ test_tools.py          # Local tests for each tool
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How It Works

### ğŸ”¹ Step 1 â€” **InspectTool**

Performs an **Exploratory Data Analysis (EDA)**:

* Displays dataset info (shape, dtypes, missing values)
* Generates **histograms**, **boxplots**, and **correlation heatmaps**
* Detects data imbalances and null distributions

**Example output:**

* `df.info()`, `df.describe()`
* Automatic visualizations for numeric variables
* Summary of missing data

---

### ğŸ”¹ Step 2 â€” **CleaningTool**

Cleans and prepares the dataset:

* Removes duplicates
* Handles missing values (median or mode)
* Encodes categorical variables (LabelEncoder or OneHotEncoder)
* Scales numerical columns (StandardScaler)
* Detects and drops low-variance features

**Goal:** produce a dataset ready for model training.

---

### ğŸ”¹ Step 3 â€” **TrainTool**

Automatically trains a model based on target variable type:

* Detects whether itâ€™s **classification** or **regression**
* Chooses the appropriate **RandomForest** model
* Runs **GridSearchCV** to optimize hyperparameters
* Splits data into train/test (80/20)
* Displays key metrics:

  * Classification: `Accuracy`, `Precision`, `Recall`, `F1`
  * Regression: `RMSE`, `RÂ²`

---

## âš™ï¸ Installation

### Prerequisites

* Python â‰¥ 3.11
* Virtual environment recommended

```bash
git clone https://github.com/MeidiLprog/datacleaner-agent.git
cd datacleaner-agent
pip install -r requirements.txt
```

---

## ğŸ§­ Usage

### â–¶ï¸ Run the agent

```bash
python app.py
```

The agent will:

1. Load the Titanic dataset (default)
2. Inspect and clean it automatically
3. Train a predictive model on `Survived`
4. Output key metrics and model summary

**Expected Output:**

```
Dataset successfully loaded ! (891, 12)
Agent ready !
Inspecting dataset...
Cleaning done...
GridSearch training...
Accuracy: 0.84
F1 Score: 0.81
```

---

## â˜ï¸ Supported Execution Modes

### ğŸŸ¡ Hugging Face Cloud (Recommended)

Runs the reasoning model via Hugging Face Inference API.

Set your token:

```bash
export HUGGINGFACEHUB_API_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxxxxxx"
```

Then in `agent_logic.py`:

```python
model = LiteLLMModel(model_id="huggingface/mistralai/Mistral-7B-Instruct-v0.2")
```

### ğŸ”µ Local (Offline) â€“ Ollama

If you prefer running locally:

1. Install [Ollama](https://ollama.com)
2. Pull the model:

   ```bash
   ollama pull qwen2:1.5b
   ```
3. Replace model in `agent_logic.py`:

   ```python
   model = LiteLLMModel(model_id="ollama/qwen2:1.5b")
   ```

---

## ğŸ§° Technologies Used

| Stack                      | Purpose                            |
| -------------------------- | ---------------------------------- |
| ğŸ¤— Hugging Face SmolAgents | Agent orchestration                |
| ğŸ”® LiteLLM / HfApiModel    | LLM reasoning                      |
| ğŸ§¹ Pandas / Numpy          | Data wrangling                     |
| ğŸ“Š Matplotlib / Seaborn    | Data visualization                 |
| âš™ï¸ Scikit-Learn            | Model training & GridSearch        |
| ğŸ’» Ollama                  | Local LLM inference (offline mode) |

---

## ğŸ’¡ Example Screenshots

| Visualization                    | Description                          |
| -------------------------------- | ------------------------------------ |
| ![EDA](assets/eda.png)           | Automatic data histograms & boxplots |
| ![Heatmap](assets/heatmap.png)   | Correlation matrix                   |
| ![Training](assets/training.png) | Model training output                |

---

## ğŸ§‘â€ğŸ’» Author

**Lefki Meidi**
ğŸ“ Data Science & Machine Learning Engineer
ğŸ’¬ [LinkedIn](https://www.linkedin.com/in/lefkimeidi) â€¢ [GitHub](https://github.com/MeidiLprog) â€¢ [HuggingFace](https://huggingface.co/Meidilefki)

---

## ğŸŒŸ Project Highlights

* Built **entirely from scratch** in less than 24h
* Modular architecture (plug & play tools)
* Hugging Face AI agent integrated locally **and** via cloud API
* Fully autonomous workflow: from raw data â†’ cleaned dataset â†’ trained model
* Ideal for data preprocessing automation or teaching agent reasoning

---

## â¤ï¸ Acknowledgements

Special thanks to **Hugging Face** for the SmolAgents framework, and the open-source community for making AI accessible.

> â€œWhy spend hours cleaning data when your agent can do it for you?â€
